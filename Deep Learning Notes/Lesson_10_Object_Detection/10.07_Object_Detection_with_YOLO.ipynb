{"cells":[{"cell_type":"markdown","metadata":{"id":"KVMTPn5-GmbA"},"source":["# Object Detection with YOLO\n","- YOLO is short for You Only Look Once.\n","- It is a family of single-stage deep learning-based object detectors.\n","- They are capable of more than real-time object detection with state-of-the-art accuracy."]},{"cell_type":"markdown","metadata":{"id":"Epr2lBRrd19k"},"source":["## Steps to  be followed:\n","\n","1. Import the necessary libraries\n","2. Define the hyperparameter values\n","3. Define a helper function to download files\n","4. Pull the data from Roboflow\n","5. Clone the **YOLOv5** repository\n","6. Create a directory to store results\n","7. Run the model\n","8. Define a function to show validation predictions saved during training\n","9. Define a helper function for inference on images\n","10. Visualize inference images\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-VcqkxnxHrHD"},"source":["### Step 1: Import the necessary libraries\n","- Import the **os** module for operating system-related functionalities.\n","- Import the **glob** module for file path pattern matching.\n","- Import the **matplotlib.pyplot** module for plotting.\n","- Import the **OpenCV** module for image processing.\n","- Import the **requests** module for making HTTP requests.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VKR3rGJoa-H7"},"outputs":[],"source":["import os\n","import glob as glob\n","import matplotlib.pyplot as plt\n","import cv2\n","import requests\n"]},{"cell_type":"markdown","metadata":{"id":"Vq0COFzOIcOf"},"source":["### Step 2: Define the hyperparameter values\n","- Define the number of epochs to train."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iagY3DkfbASa"},"outputs":[],"source":["TRAIN = True\n","EPOCHS = 5"]},{"cell_type":"markdown","metadata":{"id":"hHpBJBoyjGy2"},"source":["__Observations:__\n","\n","The code specifies that the training will be conducted over a total of 5 epochs."]},{"cell_type":"markdown","metadata":{"id":"XWE3o4JmIrLi"},"source":["### Step 3: Define a helper function to download files\n","- Download a file from the provided URL and save it with the specified name.\n","- Send an HTTP GET request to the URL to download the file.\n","- Write the content of the response to a file using the specified name.\n","- If the file already exists, display a message indicating that the download has been skipped.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NkKvWGMUbIvu"},"outputs":[],"source":["def download_file(url, save_name):\n","    if not os.path.exists(save_name):\n","        file = requests.get(url)\n","        open(save_name, 'wb').write(file.content)\n","    else:\n","        print('File already present, skipping download...')\n"]},{"cell_type":"markdown","metadata":{"id":"QULXj2CVGmbK"},"source":["### About the dataset:\n","- The dataset comprises images depicting different vehicles in diverse traffic conditions. These images have been sourced from the Open Image dataset.\n","- In total, the dataset consists of 5 classes, namely: Car, Bus, Motorcycle, Truck, and Ambulance."]},{"cell_type":"markdown","metadata":{"id":"8tAUoYfKJS-W"},"source":["### Step 4: Pull the data from Roboflow\n","\n","-  If the **train** directory doesn't exist, download the dataset zip file from the specified URL using curl.\n","- Unzip the downloaded file and remove the zip file after extraction.\n","- Create a list of directory names: **train, valid, test**.\n","- Iterate over each directory name and its corresponding index.\n","- Get a sorted list of all image names in the current directory.\n","- Iterate over each image name and its corresponding index.\n","- If the index is even (i.e., every second image), extract the file name without the extension.\n","- Remove the image file.\n","- Remove the corresponding label file.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eZ-caJ4KbN-z"},"outputs":[],"source":["if not os.path.exists('train'):\n","\n","    !/usr/bin/curl -L \"https://public.roboflow.com/ds/xKLV14HbTF?key=aJzo7msVta\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n","    dirs = ['train', 'valid', 'test']\n","    for i, dir_name in enumerate(dirs):\n","        all_image_names = sorted(os.listdir(f\"{dir_name}/images/\"))\n","        for j, image_name in enumerate(all_image_names):\n","            if (j % 2) == 0:\n","                file_name = image_name.split('.jpg')[0]\n","                os.remove(f\"{dir_name}/images/{image_name}\")\n","                os.remove(f\"{dir_name}/labels/{file_name}.txt\")\n"]},{"cell_type":"markdown","metadata":{"id":"NKDHsJ-1rhMN"},"source":["**Observations:**\n","\n","The code block downloads a dataset, extracts it, and selectively removes certain image and label files from the directories."]},{"cell_type":"markdown","metadata":{"id":"Qj09tX2NKlcf"},"source":["### Step 5: Clone the YOLOv5 repository\n","- If the **YOLOv5** directory does not exist, clone the **YOLOv5** repository from the provided GitHub URL.\n","- Change the current working directory to **YOLOv5**.\n","- Install the necessary Python packages listed in the **requirements.txt** file.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6216,"status":"ok","timestamp":1716032129415,"user":{"displayName":"Vikas Singh","userId":"04375885343580620832"},"user_tz":-330},"id":"JvZ3O5n3bWGM","outputId":"ac138e48-cc96-4678-82d0-1f3db309445e"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/yolov5\n","Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.1.43)\n","Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n","Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.25.2)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.8.0.76)\n","Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (10.3.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.11.4)\n","Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (0.1.1.post2209072238)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.2.1+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.17.1+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.66.4)\n","Requirement already satisfied: ultralytics>=8.0.232 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (8.2.17)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (2.0.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.13.1)\n","Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (67.7.2)\n","Requirement already satisfied: wheel>=0.38.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 50)) (0.43.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.11)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (24.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2024.2.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.0.232->-r requirements.txt (line 18)) (9.0.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2024.1)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n"]}],"source":["if not os.path.exists('yolov5'):\n","\n","    !git clone https://github.com/ultralytics/yolov5.git\n","\n","%cd yolov5/\n","\n","!pip3 install -r requirements.txt\n"]},{"cell_type":"markdown","metadata":{"id":"OTR6vjg3r793"},"source":["**Observations:**\n","\n","The code block checks for the presence of the **YOLOv5** project directory, clones it (if necessary), sets it as the current working directory, and installs the required dependencies."]},{"cell_type":"markdown","metadata":{"id":"WE5OQKTdLC8z"},"source":["### Step 6: Create a directory to store results\n","- Set the directory to store results based on the current number of result directories.\n","- Count the number of result directories in the **runs/train** directory. If the **TRAIN** variable is **True** (assuming it's defined outside of this function), then set the result directory name with an incremented count.\n","- Otherwise, set the result directory name without incrementing the count.\n","- Return the name of the result directory.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5POEGBnPd22Q"},"outputs":[],"source":["def set_res_dir():\n","    # Directory to store results\n","    res_dir_count = len(glob.glob('runs/train/*'))\n","    print(f\"Current number of result directories: {res_dir_count}\")\n","    if TRAIN:\n","        RES_DIR = f\"results_{res_dir_count+1}\"\n","        print(RES_DIR)\n","    else:\n","        RES_DIR = f\"results_{res_dir_count}\"\n","    return RES_DIR"]},{"cell_type":"markdown","metadata":{"id":"IUIT7bBoLKYu"},"source":["### Step 7: Run the model\n","- Set the **RES_DIR** variable by calling the **set_res_dir()** function.\n","- If the **TRAIN** variable is **True**, execute the **train.py** script with the specified command-line arguments.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":135405,"status":"ok","timestamp":1716032264811,"user":{"displayName":"Vikas Singh","userId":"04375885343580620832"},"user_tz":-330},"id":"cAV9ko5LboAl","outputId":"a3148bcc-57d4-4133-bf91-d029e94fddf6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Current number of result directories: 1\n","results_2\n","2024-05-18 11:35:36.666752: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-18 11:35:36.666815: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-18 11:35:36.684920: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=../data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=results_2, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n","YOLOv5 ðŸš€ v7.0-312-g1bcd17ee Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ðŸš€ runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Overriding model.yaml nc=80 with nc=5\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     26970  models.yolo.Detect                      [5, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model summary: 214 layers, 7033114 parameters, 7033114 gradients, 16.0 GFLOPs\n","\n","Transferred 343/349 items from yolov5s.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/train/labels.cache... 439 images, 0 backgrounds, 0 corrupt: 100% 439/439 [00:00<?, ?it/s]\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/valid/labels.cache... 125 images, 0 backgrounds, 0 corrupt: 100% 125/125 [00:00<?, ?it/s]\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.85 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n","Plotting labels to runs/train/results_2/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/results_2\u001b[0m\n","Starting training for 5 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","        0/4      3.67G     0.1013     0.0358      0.048         23        640: 100% 28/28 [00:22<00:00,  1.23it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:03<00:00,  1.01it/s]\n","                   all        125        227      0.509     0.0487      0.087     0.0326\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","        1/4      4.49G    0.07396    0.03271    0.03633         33        640: 100% 28/28 [00:10<00:00,  2.59it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:02<00:00,  1.34it/s]\n","                   all        125        227       0.23      0.351       0.18     0.0799\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","        2/4      4.49G    0.06406     0.0302     0.0304         33        640: 100% 28/28 [00:12<00:00,  2.25it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:02<00:00,  1.66it/s]\n","                   all        125        227      0.289      0.407      0.275      0.119\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","        3/4      4.49G    0.05787    0.02758    0.02672         23        640: 100% 28/28 [00:14<00:00,  1.98it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:02<00:00,  1.80it/s]\n","                   all        125        227       0.27      0.433      0.342       0.16\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","        4/4      4.49G    0.05557    0.02594    0.02669         16        640: 100% 28/28 [00:14<00:00,  2.00it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:02<00:00,  1.43it/s]\n","                   all        125        227      0.317      0.524      0.364      0.193\n","\n","5 epochs completed in 0.026 hours.\n","Optimizer stripped from runs/train/results_2/weights/last.pt, 14.5MB\n","Optimizer stripped from runs/train/results_2/weights/best.pt, 14.5MB\n","\n","Validating runs/train/results_2/weights/best.pt...\n","Fusing layers... \n","Model summary: 157 layers, 7023610 parameters, 0 gradients, 15.8 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:03<00:00,  1.02it/s]\n","                   all        125        227      0.319      0.523      0.364      0.194\n","             Ambulance        125         32      0.413      0.312       0.32      0.161\n","                   Bus        125         23      0.264      0.826      0.479      0.233\n","                   Car        125        119      0.212      0.605      0.344      0.184\n","            Motorcycle        125         23      0.446      0.739      0.555      0.318\n","                 Truck        125         30      0.262      0.133      0.124     0.0724\n","Results saved to \u001b[1mruns/train/results_2\u001b[0m\n"]}],"source":["RES_DIR = set_res_dir()\n","if TRAIN:\n","    # VOC: python3\n","    !python3 train.py --data ../data.yaml --weights yolov5s.pt \\\n","    --img 640 --epochs {EPOCHS} --batch-size 16 --name {RES_DIR}\n","\n"]},{"cell_type":"markdown","metadata":{"id":"TIaa1FYdtG7Z"},"source":["**Observations:**\n","\n","The code sets a results directory using **set_res_dir()**. If **TRAIN** is **True**, it executes a **YOLOv5** training command with specific arguments, saving the results in the results directory."]},{"cell_type":"markdown","metadata":{"id":"J_Nzmc3OMgZO"},"source":["### Step 8: Define a function to show validation predictions saved during training\n","- List the contents of the **runs/train/{RES_DIR}** directory.\n","- Set the **EXP_PATH** variable as the path to the result directory.\n","- Get a list of paths to predicted images in the result directory.\n","- Print the list of predicted image paths.\n","- Iterate over each predicted image path.\n","- Read the image using **OpenCV**.\n","- Create a figure with a specific size.\n","- Display the image (converting BGR to RGB) and turn off the axes.\n","- Show the image.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QbFfwx9Vbuwp"},"outputs":[],"source":["def show_valid_results(RES_DIR):\n","    !ls runs/train/{RES_DIR}\n","    EXP_PATH = f\"runs/train/{RES_DIR}\"\n","    validation_pred_images = glob.glob(f\"{EXP_PATH}/*_pred.jpg\")\n","    print(validation_pred_images)\n","    for pred_image in validation_pred_images:\n","        image = cv2.imread(pred_image)\n","        plt.figure(figsize=(19, 16))\n","        plt.imshow(image[:, :, ::-1])\n","        plt.axis('off')\n","        plt.show()"]},{"cell_type":"markdown","metadata":{"id":"NpPou7ufNK6W"},"source":["### Step 9: Define a helper function for inference on images\n","- Perform inference on images using the specified result directory.\n","- Create a directory to store inference results.\n","- Count the number of inference-detection directories.\n","- Set the inference-detection directory name with an incremented count.\n","- Execute the **detect.py** script with the specified command-line arguments.\n","- Return the name of the inference detection directory.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D5LSNzgYfPK9"},"outputs":[],"source":["def inference(RES_DIR, data_path):\n","\n","    infer_dir_count = len(glob.glob('runs/detect/*'))\n","    print(f\"Current number of inference detection directories: {infer_dir_count}\")\n","    INFER_DIR = f\"inference_{infer_dir_count+1}\"\n","    print(INFER_DIR)\n","\n","    !python3 detect.py --weights runs/train/{RES_DIR}/weights/best.pt \\\n","    --source {data_path} --name {INFER_DIR}\n","    return INFER_DIR"]},{"cell_type":"markdown","metadata":{"id":"1bG1x155N0VP"},"source":["### Step 10: Visualize inference images\n","- Perform inference on images using the specified result directory.\n","- Create a directory to store inference results.\n","- Count the number of inference-detection directories.\n","- Set the inference detection directory name with an incremented count.\n","- Execute the **detect.py** script with the specified command-line arguments and return the name of the inference detection directory.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZbbSdZzIfU3o"},"outputs":[],"source":["def visualize(INFER_DIR):\n","\n","    INFER_PATH = f\"runs/detect/{INFER_DIR}\"\n","    infer_images = glob.glob(f\"{INFER_PATH}/*.jpg\")\n","    print(infer_images)\n","    for pred_image in infer_images:\n","        image = cv2.imread(pred_image)\n","        plt.figure(figsize=(19, 16))\n","        plt.imshow(image[:, :, ::-1])\n","        plt.axis('off')\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1BMEWbVQC5u0IizLeyF9BJBBWuJkIPxqR"},"executionInfo":{"elapsed":68786,"status":"ok","timestamp":1716032333573,"user":{"displayName":"Vikas Singh","userId":"04375885343580620832"},"user_tz":-330},"id":"ifypsTODfa6J","outputId":"5197264e-2223-4439-a866-52ad416141c7"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["show_valid_results(RES_DIR)"]},{"cell_type":"markdown","metadata":{"id":"qbW2IrATtc3p"},"source":["**Observations:**\n","\n","The code defines a function that retrieves inference images from a specified directory. It loads and visualizes each image using OpenCV and Matplotlib, respectively, and displays them."]},{"cell_type":"markdown","metadata":{"id":"kMFHAaASOZZI"},"source":["#### Download the inference data file\n","- If the **inference_images** directory doesn't exist, extract the contents of the **inference_data.zip** file.\n","- Else, print a message indicating that the dataset is already present.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"69h3MRNIfeT3"},"outputs":[],"source":["download_file('https://learnopencv.s3.us-west-2.amazonaws.com/yolov5_inference_data.zip',\n","              'inference_data.zip')\n","if not os.path.exists('inference_images'):\n","    !unzip -q \"inference_data.zip\"\n","else:\n","    print('Dataset already present')"]},{"cell_type":"markdown","metadata":{"id":"TjyOP7kaO9Wz"},"source":["#### Inference on images\n","- Call the **inference** function with the arguments **RES_DIR** and **inference_images**.\n","- Assign the output to the variable **IMAGE_INFER_DIR**.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39,"status":"ok","timestamp":1716032333573,"user":{"displayName":"Vikas Singh","userId":"04375885343580620832"},"user_tz":-330},"id":"aUhFthwdfnH3","outputId":"b8012db2-b3eb-4402-a13a-9e4265f16a01"},"outputs":[{"name":"stdout","output_type":"stream","text":["Current number of inference detection directories: 0\n","inference_1\n","\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/results_2/weights/best.pt'], source=inference_images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=inference_1, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLOv5 ðŸš€ v7.0-312-g1bcd17ee Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","Fusing layers... \n","Model summary: 157 layers, 7023610 parameters, 0 gradients, 15.8 GFLOPs\n","WARNING âš ï¸ NMS time limit 0.550s exceeded\n","image 1/4 /content/yolov5/inference_images/image_1.jpg: 448x640 1 Bus, 6 Cars, 52.6ms\n","image 2/4 /content/yolov5/inference_images/image_2.jpg: 416x640 2 Cars, 48.1ms\n","image 3/4 /content/yolov5/inference_images/image_3.jpg: 448x640 1 Bus, 8.6ms\n","image 4/4 /content/yolov5/inference_images/image_4.jpg: 480x640 3 Cars, 50.3ms\n","Speed: 0.5ms pre-process, 39.9ms inference, 146.0ms NMS per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/inference_1\u001b[0m\n"]}],"source":["IMAGE_INFER_DIR = inference(RES_DIR, 'inference_images')"]},{"cell_type":"markdown","metadata":{"id":"s-W4ixiiPiFE"},"source":["#### Visualizing the inference results\n","- Invoke the **visualize** function and pass the variable **IMAGE_INFER_DIR** as an argument.\n","- The visualize function displays the contents of the directory or file represented by the **IMAGE_INFER_DIR** variable."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":868,"output_embedded_package_id":"1BAe0N1YudJNonJF_F9KvbSmWXGjDBmOe"},"id":"-kKyRn_8ftuo","outputId":"cf46f92a-4437-42d2-a669-fbc0d7b7adc1"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["visualize(IMAGE_INFER_DIR)"]},{"cell_type":"markdown","metadata":{"id":"395U97i4t4Er"},"source":["**Observations:**\n","\n"," The content associated with the directory or file is displayed."]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}